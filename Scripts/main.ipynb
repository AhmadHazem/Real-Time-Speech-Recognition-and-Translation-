{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structred Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# System Libraries\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import nltk\n",
    "\n",
    "# Garbage Collection\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Whisper Model\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Helsinki-NLP\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Evaluation\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\Real-Time-Speech-Recognition-and-Translation-\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "DIRECTORY_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "VALIDATED_DATA_PATH = r\"\\Common_Voice\\validated.tsv\"\n",
    "VALIDATED_SENTENCES_PATH = r\"\\Common_Voice\\unvalidated_sentences.tsv\"\n",
    "CLIP_DURATION_PATH = r\"\\Common_Voice\\clip_durations.tsv\"\n",
    "CLIPS_PATH = r\"\\Common_Voice\\clips\\\\\"\n",
    "CLIPS_WAV_PATH = r\"\\Common_Voice\\clips_wav\\\\\"\n",
    "\n",
    "# Constants\n",
    "NYQUIST_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(62802, 512, padding_idx=62801)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(62802, 512, padding_idx=62801)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(62802, 512, padding_idx=62801)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=62802, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Whisper Model\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load Helsinki-NLP Model\n",
    "model_name_translate = \"Helsinki-NLP/opus-mt-en-ar\"\n",
    "tokenizer_translation = MarianTokenizer.from_pretrained(model_name_translate)\n",
    "model_translate = MarianMTModel.from_pretrained(model_name_translate)\n",
    "model_translate.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToWav(paths):\n",
    "    # Add Padding\n",
    "    for path in paths:\n",
    "        wavform, sr = librosa.load(DIRECTORY_PATH + CLIPS_PATH + path)\n",
    "        wavform = librosa.resample(wavform, orig_sr=sr, target_sr=NYQUIST_SAMPLING_RATE)\n",
    "        sf.write(DIRECTORY_PATH + CLIPS_WAV_PATH + path[:-4] + \".wav\", wavform, sr, format='wav')\n",
    "\n",
    "def getTokenizedSentences(sentences):\n",
    "    tokenized_sentence = processor.tokenizer.tokenize(sentences)   #False --> Word\n",
    "    return tokenized_sentence\n",
    "\n",
    "def TranscribeAudios(paths):\n",
    "    Transcribed_Sentences = pipe(paths)\n",
    "    return Transcribed_Sentences\n",
    "\n",
    "def fixPaths(paths):\n",
    "    new_paths = []\n",
    "    for path in paths:\n",
    "        new_paths.append( DIRECTORY_PATH + CLIPS_WAV_PATH + path[:-4] + \".wav\")\n",
    "    return new_paths\n",
    "\n",
    "def CalculateAvgBLEUScore(Transcribed_Sentences, Validated_Sentences, tokenizer):\n",
    "    BLEU_Scores = []\n",
    "    for i in range(len(Transcribed_Sentences)):\n",
    "        Valid_Sentence = tokenizer.tokenize(Validated_Sentences[i])\n",
    "        Transcribed_Sentence = tokenizer.tokenize(Transcribed_Sentences[i]['text'])\n",
    "        BLEU_Scores.append(nltk.translate.bleu_score.sentence_bleu([Valid_Sentence], Transcribed_Sentence))\n",
    "    return np.mean(BLEU_Scores)\n",
    "\n",
    "def CalculateAvgROUGEScore(Transcribed_Sentences, Validated_Sentences):\n",
    "    rs = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    ROUGE1_Percision_Scores = []\n",
    "    ROUGE1_Recall_Scores = []\n",
    "    ROUGE1_F1_Scores = []\n",
    "    ROUGE2_Percision_Scores = []\n",
    "    ROUGE2_Recall_Scores = []\n",
    "    ROUGE2_F1_Scores = []\n",
    "    ROUGEL_Percision_Scores = []\n",
    "    ROUGEL_Recall_Scores = []\n",
    "    ROUGEL_F1_Scores = []\n",
    "    for i in range(len(Transcribed_Sentences)):\n",
    "        rouge_score = rs.score(Validated_Sentences[i], Transcribed_Sentences[i]['text'])\n",
    "        ROUGE1_Percision_Scores.append(rouge_score['rouge1'][0])\n",
    "        ROUGE1_Recall_Scores.append(rouge_score['rouge1'][1])\n",
    "        ROUGE1_F1_Scores.append(rouge_score['rouge1'][2])\n",
    "        ROUGE2_Percision_Scores.append(rouge_score['rouge2'][0])\n",
    "        ROUGE2_Recall_Scores.append(rouge_score['rouge2'][1])\n",
    "        ROUGE2_F1_Scores.append(rouge_score['rouge2'][2])\n",
    "        ROUGEL_Percision_Scores.append(rouge_score['rougeL'][0])\n",
    "        ROUGEL_Recall_Scores.append(rouge_score['rougeL'][1])\n",
    "        ROUGEL_F1_Scores.append(rouge_score['rougeL'][2])\n",
    "    return {\"rouge1\" : [np.mean(ROUGE1_Percision_Scores), np.mean(ROUGE1_Recall_Scores), np.mean(ROUGE1_F1_Scores)], \n",
    "            \"rouge2\" : [np.mean(ROUGE2_Percision_Scores), np.mean(ROUGE2_Recall_Scores), np.mean(ROUGE2_F1_Scores)],\n",
    "            \"rougeL\" : [np.mean(ROUGEL_Percision_Scores), np.mean(ROUGEL_Recall_Scores), np.mean(ROUGEL_F1_Scores)]}\n",
    "        \n",
    "def TranslateSentence(Transcribed_Sentences):\n",
    "    Translated_Sentences = []\n",
    "    for sentence in Transcribed_Sentences:\n",
    "        batch = tokenizer_translation([sentence['text']], return_tensors=\"pt\")\n",
    "        generated_ids = model_translate.generate(batch[\"input_ids\"].to(device))\n",
    "        Translated_Sentences.append(tokenizer_translation.batch_decode(generated_ids, skip_special_tokens=True)[0])\n",
    "    return Translated_Sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AudioPreprocessing\n",
    "unfiltered_dataset = pd.read_csv(DIRECTORY_PATH + VALIDATED_DATA_PATH , sep='\\t')[[\"path\", \"sentence\", \"up_votes\"]]\n",
    "ConvertToWav(unfiltered_dataset[\"path\"].tolist())\n",
    "unfiltered_dataset[\"path\"] = fixPaths(unfiltered_dataset[\"path\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:599: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Transcribe (Do NOT Run this cell it is time consuming)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Transcribed_Sentences \u001b[38;5;241m=\u001b[39m \u001b[43mTranscribeAudios\u001b[49m\u001b[43m(\u001b[49m\u001b[43munfiltered_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m Real_Sentences \u001b[38;5;241m=\u001b[39m unfiltered_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mTranscribeAudios\u001b[1;34m(paths)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTranscribeAudios\u001b[39m(paths):\n\u001b[1;32m---> 13\u001b[0m     Transcribed_Sentences \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Transcribed_Sentences\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:284\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    223\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    225\u001b[0m ):\n\u001b[0;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1249\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1246\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1247\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[1;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:512\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[1;34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    510\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 512\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    513\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    514\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq_whisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:671\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[1;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m             proc\u001b[38;5;241m.\u001b[39mset_begin_index(decoder_input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;66;03m# 6.6 Run generate with fallback\u001b[39;00m\n\u001b[0;32m    665\u001b[0m (\n\u001b[0;32m    666\u001b[0m     seek_sequences,\n\u001b[0;32m    667\u001b[0m     seek_outputs,\n\u001b[0;32m    668\u001b[0m     should_skip,\n\u001b[0;32m    669\u001b[0m     do_condition_on_prev_tokens,\n\u001b[0;32m    670\u001b[0m     model_output_type,\n\u001b[1;32m--> 671\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegment_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcur_bsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_bsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseek\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_shortform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# 6.7 In every generated sequence, split by timestamp tokens and extract segments\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, seek_sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seek_sequences):\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:834\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate_with_fallback\u001b[1;34m(self, segment_input, decoder_input_ids, cur_bsz, batch_idx_map, seek, num_segment_frames, max_frames, temperatures, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_token_timestamps, do_condition_on_prev_tokens, is_shortform, batch_size, attention_mask, kwargs)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    830\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    831\u001b[0m             generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, batch_size \u001b[38;5;241m-\u001b[39m cur_bsz), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    832\u001b[0m         )\n\u001b[1;32m--> 834\u001b[0m seek_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    835\u001b[0m     segment_input,\n\u001b[0;32m    836\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m    837\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    838\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m    839\u001b[0m     prefix_allowed_tokens_fn\u001b[38;5;241m=\u001b[39mprefix_allowed_tokens_fn,\n\u001b[0;32m    840\u001b[0m     synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m    841\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m    842\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m    844\u001b[0m )\n\u001b[0;32m    846\u001b[0m model_output_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(seek_outputs)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# post-process sequence tokens and outputs to be in list form\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1864\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1864\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:512\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[0;32m    510\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    511\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 512\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:1121\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[1;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1114\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1115\u001b[0m             hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             output_attentions,\n\u001b[0;32m   1119\u001b[0m         )\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1121\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1128\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:689\u001b[0m, in \u001b[0;36mWhisperEncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    686\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m--> 689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    690\u001b[0m     torch\u001b[38;5;241m.\u001b[39misinf(hidden_states)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(hidden_states)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    691\u001b[0m ):\n\u001b[0;32m    692\u001b[0m     clamp_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(hidden_states\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmax \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m    693\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(hidden_states, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mclamp_value, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mclamp_value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transcribe (Do NOT Run this cell it is time consuming)\n",
    "Transcribed_Sentences = TranscribeAudios(unfiltered_dataset[\"path\"].tolist())\n",
    "Real_Sentences = unfiltered_dataset[\"sentence\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Pickle_Files/Transcribed_Sentences.pkl', 'rb') as f:\n",
    "    Transcribed_Sentences = pickle.load(f)\n",
    "Real_Sentences = unfiltered_dataset[\"sentence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.6801078611053675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\BLU-RAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU Score\n",
    "BLEU_Score = CalculateAvgBLEUScore(Transcribed_Sentences, Real_Sentences, processor.tokenizer)\n",
    "print(f\"BLEU Score: {BLEU_Score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Precision           | Recall             | F1\n",
      "Rouge_1 Score: [0.9415822418889903, 0.9426635481083333, 0.9419391677910781]\n",
      "Rouge_2 Score: [0.9064298857243641, 0.9075811032866249, 0.906802859490404]\n",
      "Rouge_L Score: [0.9415822418889903, 0.9426635481083333, 0.9419391677910781]\n"
     ]
    }
   ],
   "source": [
    "ROUGE_Scores = CalculateAvgROUGEScore(Transcribed_Sentences, Real_Sentences)\n",
    "print(\"               Precision           | Recall             | F1\")\n",
    "print(f\"Rouge_1 Score: {ROUGE_Scores['rouge1']}\")\n",
    "print(f\"Rouge_2 Score: {ROUGE_Scores['rouge2']}\")\n",
    "print(f\"Rouge_L Score: {ROUGE_Scores['rougeL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['إنها تخفي حزنها وتنضم إلى احتفالات العودة للوطن', 'ومكث روكشيك في قصر صديقه الشخصي، الدكتاتور فيرنانديز ماركوس.', 'كان لديها حياة وظيفية غير مستقرة.', 'دعنا نأكل الشوكولاتة الليلة', '(نيوبورت) كانت مقاطعة.', 'نموذج هيكمان يقع في هذا النوع.', 'وفقدت هذه الكتابة أسطولا من الحبوب في الركن الريفي الجنوبي الغربي من سانت كاتارنيس.', 'ويتميز بكاميرا نهارية وليلية وتتابع الفيديو.', 'والصيغ الأكثر حداثة للضريبة لم تعد تتطلب طابعا فعليا.', 'ويستند التصنيف إلى توقيت الاستخلاص الذي ينظم مؤقتاً.', 'لقد وضع جليسة بيضاء على العشاء', 'وهي تشكل أكبر بحيرة اصطناعية في ماوي، بحيرة مانانتالي.', '(فوكس) قام بتكرار بث البرنامج مراراً وتكراراً ليفسح المجال لعروض أخرى.', 'وأنتج فيرنر أشرطة فيديو وثائقية قصيرة عن التاريخ القانوني والقانون المقارن.', 'عندما شخص اللاعب يلمس وحشاً، يموتون.', 'وافتتح مؤخرا مكتبا الجمارك وحماية الحدود في مبنى الشحن السابق في أقصى الشرق.', 'حصل زملاء الدراسة والأصدقاء على منحة دراسية باسمه في كارنيج ميلن.', 'وقد نشأ ذلك في الازمنة التي لم يُسمح فيها للرقيق ان يلعبوا الآلات الموسيقية .', 'في خريف تلك السنة، قامت بجولة منفردة مع فرقتها في سويسرا.', 'وبيوت البناء، والفصول الدراسية، والمراحيض، والحمامات، وغرفة الموظفين.', '(لقد كان لقبها (لونغ ليز', 'ويتأهل الفائزون في كل مجموعة من الازياء ، التي تكون اعلى من الجريئة ، للجولة التالية .', 'وقد انتقلت أسر كثيرة إلى هذه المنازل.', 'يبدو أن من المرجح أن يكون قد لعب مع أعداد متساوية على كلا الجانبين.', 'وقد تلقت الأكاديمية الجوية استحساناً وطنياً على العديد من مجموعاتها الفعالة.', 'الاتصال بالدكتور كُتب في ثلاثة أسابيع و سُجّل في أربعة أيام.', 'تقاعد من كرة السلة بعد الموسم', 'وللاطلاع على مزيد من التفاصيل عن التكوين الكريستالي الجيولوجي، انظر أعلاه.', 'وتبين هذه الوثيقة أن الكنيسة الكاثوليكية تنتقل رسميا إلى الوحدة.', 'وأدى الزواج إلى انشقاق بين الأم وابنها.', 'فكثيراً ما يبني مشروع القانون ولاياته الاستثمارية من أجل تحقيق أهداف محددة.', 'وكان لا بد من ربط دعمها بالمنسا.', 'وقد تم تسليم الوقود عن طريق حقن وقود متعدد الموانئ.', 'ولا يجوز سقوط أي شجرة على الأرض المقدسة.', 'وعلى الرغم من حركة الألغام البرية، استمر القتال في جميع أنحاء البلد.', 'السيد (مالوري) صدمته سيارة وهو في طريقه للعمل', 'وهو غير مستخدم على هذا النحو في انكلترا.', 'وكان إنتاج ماش إلدالون نتيجة لتصحيح كره للتماثل.', 'تمويه مدرسة (كارلسون) الثانوية هو السيناتور', 'ويندرج تحليل شبكة النقل في مجال هندسة النقل.', 'وسأستعرض بعض التطورات الملحوظة في الاقتصاد والنظام المالي.', '(ترينت) يعمل على تأمين مقاتل صغير ويغادر إلى (سيفيرا)', 'الناس دائماً ما يتراجعون في ممرات صغيرة في البلاد ليتركوك تمر.', 'وقد دُعي القدماء ايضا حوريات لمظهرهم المشترك في الهواء .', 'وهذا سيؤدي إلى مشاركة أكثر فعالية من جانب المريض.', 'ويمكن للأنواع التي تحتوي على مجموعتين أو ثلاث مجموعات من الكاثودات الإرشادية أن تحسب في أي من الاتجاهين.', 'وفي بريطانيا، تظهر السجلات الأولى لهذا اللقب بصورة رئيسية في البلاد الغربية.', 'وكان هذا الاكتشاف الرائع لم يسبق له مثيل في ذلك الوقت.', 'وهناك حاجة إلى مناظير ذات فتحات من أو أكبر لتمييز الهياكل في المجرة.', 'كان اسمه عيد الميلاد في أرض الحوريات.', 'غرفة التخزين الواحدة تحتوي على مقصورات مقفلة', 'ويستضيفها آن - ماري مديواكي وبن موروني.', 'وقرر كاليدونيا التقدم بطلب العضوية، كما فعل منافسو المدينة إنفرنيس ثتل.', 'الخطوط الأطول لها أربع لكنات والأقصر عادةً ثلاثة فقط', 'ويرتبط هذا المستوى الأعلى بنُهج فردية قوية لحل المشاكل والإبداع.', 'النهاية تعني أيضاً أن قوتها تجاوزت قوة (كارين)', 'وتفتح القرية أبوابها في نهاية كل أسبوع من أيار/مايو إلى نهاية أيلول/سبتمبر.', 'ويستخدم المخطِّطون برامجيات تحرير غير خطّية على الحواسيب المنـزلية.', 'وهذه نظرة متقاربة إلى الطابع الرئيسي الذي يجري الاضطلاع به حالياً.', 'وهذه المؤسسة جامعة مرموقة في البرازيل.', 'برج (ماتيلدا) عند نقطة (كلاي) تم تحويله إلى متحف حرب', 'وبعد وقت قصير من توقيعه ، طُويت ألويتس وبدأ الامتياز مواثيق مونتريال .', '(فيوور) هي الكلمة الفرنسية للنسر.', 'قام بنشر أشغاله الأولى للتشيلو.', 'أولاً، لا يوجد نموذج واحد يستخدم حتى بالنسبة للغة العربية القياسية.', 'تصل مروحية (ريدموند) إلى مسرح الجريمة مع فيلم ليشاهده الجميع', 'على أية حال، ليس فقط ليس هناك أي سجل للزفاف.', 'ولا يمنح المركز درجات جامعية.', 'حركة المرور سيئة جدا اليوم، ربما لأنها عطلة نهاية أسبوع مجانية.', 'ويتم التشخيص عن طريق الفحص البيوكروسكوبي في العيادة.', 'ويشير التكرير أيضاً إلى الربط بين مفاتيح التبديل والدوائر داخل مقسم هاتفي.', 'مثل معظم عائلة (باتمان) (ستيفاني براون) ليس لديها قوى خارقة', '(أندرو) يقود ثورة ويأخذ عضواً في المجلس كرهينة', 'وسرعان ما يتحول إلى مخلوق فضائي بنفسه.', 'وقامت ليبريا بعد ذلك بتصفية ممتلكات الرعايا الألمان في ليبريا.', 'وعلى الرغم من العمل الدؤوب والبحار القاسية، لم تجد السفن سوى لغما واحدا.', '(أ) لا ينطبق على النص العربي، بل على النص العربي.', 'وقد حقق المجلس المحلي تحسناً متزامناً في المنطقة المحيطة.', 'ويمكن الإشارة بإيجاز إلى حجتنا مسبقا على النحو التالي:', 'سجلات (غينيا) العالمية تعتبرها دراجة نارية منتجة', 'والوظائف المتناسقة هي المثال التقليدي الذي ينطبق عليه مبدأ الحد الأقصى القوي.', 'وكتب أيضاً إمبراطورية من الغبار عن الغبار', 'ومع ذلك، تتاح شهرياً حسب الشهر تفاصيل المبيعات المحلية لنماذج السيارات الفردية.', 'ومع ذلك، فإنه ليس على الإطلاق عن نفسها جغرافيا.', 'وقد أنهت الآن موسمها الثالث.', 'ويرأس الجناح التنفيذي المفوض.', 'ثم يعطي المرء بناءات رياضية صارمة من الامثلة التي تُرضي هذه الاكسجينات .', '(ديفونبورت ليت)، قناة مياه من صنع الإنسان، تمر بالقرب من هنا.', 'وتصدر مجلة إيثاكا منشورا ذا حجم شبابي يسمى \" باز \" كل أسبوع.', 'وهو أحد أرقى الأبراج الفولاذية والخرسانية في العالم.', 'كمراهق في سانت لويس، ميسوري، لعب مع تشارلي كريث.', 'ويستعد خريجو المدرسة لممارسة مهنة فنية ومسرحية.', 'وعلى النقيض من ذلك، يهيمن على عملية غسل الظهر تدفق الصفائح ونقل رواسب الحمل في الأسرّة.', 'وتخدم مدرسة سيلو الثانوية سيلو سيلو.', 'ويدار العقار لمدة تتراوح بين 7 و 10 أيام.', 'الحدائق مفتوحة للجمهور يومياً.', 'يُعرّفُ الميولَ.', 'ومن ثم، فإن المدعى عليهم قد تغلبوا ولم يكن عليهم أن يدفعوا الثمن.', 'واكتشفت احدى الحطب المحلية تيارا يسير برشاقة .', 'سُميت من قبل (هومر)', 'وتنافست النساء لأول مرة في برج الفرسان.', 'وتعرضت بوياكوف للعديد من حوادث السيارات قبل الرحلة وأثناءها وبعدها.', 'مجموعة إرهابية تُدعى (كريون ليونز) تسيطر على سلاح الليزر الفضائي.', '(لقد خطبوا في (كومات جورج لودج) في (مونتومالانغا', 'Vísen sjóojojara karlin var èstu ferir érér.', 'حتى وفاته، بيتلهايم عاش في باريس.', 'كما أن المطر والرياح يسببان تبايناً زمنياً بالنسبة للميكروبيو في الغلاف الحيوي.', 'استمرّت القلعات في التحقيق في إنتشارات (لاهاسا) في غرب (أفريقيا).', 'شارك في حرب الاستقلال الأمريكية.', 'وقد أمضوا ثلاث سنوات سابقة في مخيم للاجئين في السودان.', 'ولا تزال تعمل بانتظام في أماكن حية وتظهر في التلفزيون والإذاعة.', 'كان على قائمة ما بعد الموسم حيث قام بمثول واحد بدون قتال.', 'وتضاف هذه التفاعلات مع طرق أخرى.', 'شقيقه الأكبر كان ملحن مدرسة سينمائي (جيمس هورنر)', 'وقد أُزيل الاختبار الثالث بعد ثلاث ساعات فقط من اللعب.', 'يتم تشكيل ستة إلى ثمانية أزواج من الأعصاب.', 'ونتيجة لذلك، هناك أيضا نوعان من الشوفان.', 'كما أنها تتفاوت في هندسة الربط الغليكوسيديكي.', 'وقد أعيدت تسمية هذه المجموعة لتصبح منظمة العدالة في كشمير، ثم أعيدت تسميتها باسم حزب العدالة الشعبية.', 'ومن المعروف أن صوتها عالٍ وصوتها أعلى من صوت المعجبين بالسائقين الأساسيين.', 'كما يتم أيضاً إعداد قطع من مختلف العروض والأصناف ليشتريها الناس.', 'وفي ذلك الوقت، كان ماي وإرنست إيليند يعيشان منفصلين.', 'الحكومة المحلية في الأصل عارضت بناء المتحف.', 'واختطف أحد رجاله ابنه وخبأه.', 'وقبل التأسيس، كانت البلدة تعرف باسم بلدة بلايسديل.', 'ويتعاون مركز كاتا أيضاً مع منظمات أخرى من القطاعين العام والخاص', 'هذا نموذج بسيط جداً لكيفية عمل التوصيل الكامل.', 'وتعتمد عملية التوجيه بشكل كامل على الأعضاء الذين يقترحون أعضاء جددا.', 'ويعالج علم الماكروليكولوجيا فكرة دراسة النظم الإيكولوجية باستخدام نهج من القمة إلى القاعدة.', 'تَلْفُّ الطفل الرضيعَ في a شال ويَتْركُ البيتَ.', 'وبالإضافة إلى ذلك، يمكن للكثيرين، من الناحية النظرية، أن يدعموا عددا غير محدود من الأنواع.', 'راقبي نكتتك، أخبار (آي فون)، لا أستطيع.', 'إلى الشرق من التلال وجدت عصر الحديد عمل أرضي.', 'واستحوذت نسخة ليلية من التركيز على وقته في الأسبوع التالي.', 'بقي (سين) مع النادي لموسم آخر', 'وفي كل حالة، قام بيندر بصياغة التعديل وقام جو أورلاندو بسحبه.', 'قفز الكلب من أجل الفرح عند منظر صاحبها.', 'شقيقه الأصغر (آرل) تدرب كطبيب في طب العيون.', 'مجلس الشيوخ هو مجلس الشيوخ.', 'كما كانت غارات القصف اليابانية متنازعاً عليها بشدة، مع وقوع خسائر يابانية كبيرة في بعض الأحيان.', 'كما تجادل العائلة، (لوسي) تفلت من دون أن تلاحظ، غير واثقة من مستقبلها.', 'إنها طحالب بنيّة وخضراء، نبات الماء، والتربة التحتية تتراكم أكثر من اللازم.', 'ومن المحتمل أن تكون البكتيريا لديها القدرة الأكبر على استخدام الأحماض الأمينية.', 'كما أنها لعبت أيضاً في مسابقات \"لوس أنجلوس\" في دوري الأساطير لكرة القدم.', 'حصل على رتبة العقيد ومات في لندن.', 'لكن العروس لا يمكن العثور عليها في أي مكان', 'وهذه لا تتطلب ترخيص زواج.', 'وكان مهتما بصفة خاصة بتاريخ الشرق الأوسط والملاحظات اليهودية.', 'وَكَيْفَ يُمْكِنُنَا أَنْ نُحَافِظَ عَلَى ٱلْمَسِيحِيِّينَ ٱلْمَسِيحِيِّينَ ؟', 'ثمّ، يَضْربُ للأمام.', 'وفي داخل كل طابور، تُحال الحزم على أساس أساس أول في أول خروج.', 'ولا يزال بعض المشتبه فيهم في إطلاق النار مطلقي السراح.', 'وأتمت البعثة احتلال أرض ريوين عن طريق الاستيلاء على حدار في منطقة باكول.', 'تقع في مدينة إدمونتون في محافظة ألبرتا.', 'توفي في تامبا، فلوريدا ودفن في مقبرة روزلاند في مونتيسيلو.', 'ولعب لاحقاً لـ (أولد هان)', 'لم يكن كل راكبي الدراجات يتنافسون على النصر بل انضم بعضهم فقط كسياح', 'ثم تكون الأعمدة مسموحاً بها ومن ثم تكون الصفات مسموحاً بها.', 'وشملت أبحاث جوجل أيضاً هندسة الحاسوب، وأمن الحاسوب، وتصميم رموز برامجيات المعدات.', 'وتنطوي نظرية المباني على التزامات هامة في عدة مجالات متباينة إلى حد ما.', 'وتفيد التقارير بأن رابال يتبرع بجميع عائدات الكتاب إلى الأعمال الخيرية.', 'ولا يحصل القاضي على أي معلومات تجارية.', 'ولد في شيكاغو، إلينوي، نشأ توماس في بيتسبرغ، بنسلفانيا.', 'تطلقت من (غارسون) الذي تزوجته في (لندن) إلى (ماري بير)', 'ودُمرت كميات كبيرة من موائل الحيوانات.', 'المتحف سيجلس عليه وقد منح مبنى.', 'والمسرحيات المتبقية من Tetraology قد فقدت في الغالب.', 'وصل الألبوم أيضاً إلى ذروته في رقم 6 في ألمانيا، لكنه كان مصدقاً على الذهب هناك.', 'الخرطوشة مخصصة للعبة كبيرة وخطيرة', 'وقد تحقق ذلك بفضل تفاني دويغ وجفاري.', 'تم إطلاق اللعبة تحت عناوين مختلفة في كل منطقة.', 'حضر (بيرن) مدرسة (بالتيمور سيتي) الثانوية وكلية (ويك فورست)', 'تقع المقاطعة في الجزء الأوسط من جبال الغابات السوداء.', 'لديه ابنتان، ليكسي ومايا.', 'كما يظهر التباين الحاد في حواف الحروف في كل أعماله الفنية.', 'وهذا يضمن عملياً حكماً بالإعدام.', 'وقد تلقى تعليمه في مدرسة انجليكانية وتدرب كصانع وزارة.', 'وتم أيضا ترحيل التتار من شبه جزيرة القرم.', '(كان والد (نورازين) و (يوريتسون', 'وهو متزوج من كريستين غور.', 'فازت فيكتوريا في الحدث الافتتاحي.', 'لقد لوّن الصندوق بخطوط مائلة', 'كما لعب شقيقه جوستن كرة السلة في مدرسة بولدر كريك الثانوية.', 'نحن نستضيف بعض الأحداث الجديدة من الآن', 'والده كان حزيناً جداً', 'ويأتي معظم هذه الأسر من بلدة غوس كريك.', 'قاعة المدينة السابقة هي الآن مركز نورث يورك المدني.', 'وأُعلن أيضا أن التضامن منظمة قانونية.', '(ماكدونالدز) أعلنوا أنهم كانوا يبحثون في إمكانية انتهاك حقوق التأليف للاسم', 'تم تسجيلها في الأصل من قبل LaFace السجلات الفنان سام سالتر.', 'واللقاحات الموجهة هي لقاح آخر من الجيل القادم.', 'كما استبدل المتزلجون الإيطاليون عمليات السحب اللاحقة التي قام بها المتزلجون الصينيون.', 'وقد ساهم بشكل هام في تاريخ وأصل اللغة المالاوية الحديثة.', 'القرى المحيطة تُنسخ من \"ثورن\" إلى الشمال الشرقي و \"بارتلي\" إلى الجنوب الشرقي.', 'ووصل إلى المدينة مباشرة بعد أن استولى عليها الجيش الملكي الصربي.', 'مقاطعة تريمبل هي منطقة سكنية تقع في الولايات المتحدة في Trimble County.', 'من أولئك الذين حاولنا بعد ذلك للحصول على تناقض.', 'ويمكن اعتباره واحداً من مؤسسي العلوم الأبطرغرافية.', 'ويمكن للمستعملين عندئذ استخدام برامجيات تنقية المحتوى لفرض رقابة على مختلف أنواع المحتوى.', 'وهذا يمكن أن يُظهر عن طريق تحديد قيمتين عدديتين منفصلتين للمتغير الثنائي.', 'إنه مقر مجلس مدينة (ساندلاند)', 'يقع مقرها في بلدة مورا.', 'يعيش (دوك) في (سانت كلير)، (ميشيغان) مع زوجته (جويس).', 'وكانت منطقة ألين سابقاً موطناً لكادو كومانشي وغيره من الشعوب الأصلية.', 'عندما ذكر كوين أنه كان منجذباً إلى التصرف شجعه', 'وفي وقت لاحق دعا آدم لازارا للانضمام إلى الفرقة.', 'فيما يلي قائمة صربيا في بطولة التأهيل الأولمبية.', 'الـ a قرص مع افتراضي ملفات.', 'كتب فوينوس أوكهام وسكوتوس تعليقات على الترجمة الشفوية.', 'لكنّ ثورنلي قطع علاقته مع بيت بلين بعد ثلاثة اشهر فقط .', 'ويجب أن يكون المتقدمون قد أقاموا في البلد لمدة خمس سنوات.', 'وبموجب النظام الحالي، يُنتخب المشرفون حسب المقاطعة لمدة أربع سنوات.', 'ويؤخذ نفس المبدأ إلى حد أقصى في الآي-بايمز.', 'في الاساطير الجرمانية ، ايلرن هي زوجة أڠيلاز ، المرسا الاسطوري .', 'وكان يزور كروس بانتظام للحصول على المشورة.', 'وهكذا، فإن \" ماكسيمين \" في الوضع الأصلي يمثل صياغة للمساواة الاجتماعية.', 'كان مستشاراً عقارياً مع شركة عقارات قبل الدخول في السياسة', 'وأصبح هذا الأخير أكثر الأعاصير تكلفة في تاريخ ماين.', 'وللإنتاج العديد من الوظائف، والتنوع هو أساس هذا الإنتاج.', 'وهي لغة إيرانية شرقية تنتمي إلى الأسرة الهندية الأوروبية.', 'البعض سيقول صخرة تقدمية في أفضل حالاتها', 'وربما يكون هذا تخفيفا لحكم الإعدام بالغرق الذي طال أمده.', 'وتخدم القرية محطة سكة حديد جيلفوك فارغود.', '(ماك كال) كان رائداً في علاج السرطان المناعي للأطفال', 'فتاة مهذبة تم معاملتها من قبل (نيل)', 'ووجدوا أن الإجابة هي بالإيجاب.', 'في كرة القدم الأمريكية، يشير منتصف الملعب إلى خط منتصف الطريق.', 'دخلت المملكة العربية السعودية واحدة كاراتكا في البطولة الأولمبية الافتتاحية.', 'وبقياس قطر الحلقة، يمكن تقدير سنها الإجمالي.', 'وينشط كيرنر بصفة خاصة في مجالي علم البُطْن وعلم علم الأحياء وعلم الاحياء النباتية.', 'وتتمتع الجمعية الوطنية بسلطة عزل وزراء الحكومة من مناصبهم.', 'واستأنف المجلس القرار أمام المحكمة العليا.', 'تقع مدينة ميدفورد في الغالب داخل حدود المدينة.', '\"الأفلام المصوّرة تُصنّف أفلاماً للنوعية والمقبولية على حدّ سواء.\"', 'الإحتيال الأبيض مبني على نفس الكيمياء', 'لقد اندمجت مع مسرح كليفلاند', 'وقد أزيلت محطة رفع البخار ذات الصلة والمضخات الهيدروليكية.', 'في الأدغال، تتأثر (لييرا) بالمرض المميت و ستموت قريباً.', '(ميرام) تقرأ أيضاً، تُطمس نفسها.', 'حصلت على جائزة جولدن جلوب لترشيحها لهذا الدور.', 'وقد استمر في حياته المهنية بظهوره في مختلف برامج السينما والتليفزيون.', 'في القرن الـ\\u200d ١٩ ، كانت مدينة بلينڤيل تخدمها قناة المزرعة .', 'لحسن الحظ للمرضى المصابين بداء البروسوميا، الأعراض عادة ما تتناقص مع الوقت.', 'تم اختيار مكان آخر للتسليم.', 'وفي الانتخابات البرلمانية التي جرت في أيلول/سبتمبر، فاز الحزب بأربعة مقاعد.', ':: رفع مستوى التعليم في باكستان.', 'ولم يفر إلا من شي كاسينا وشي كريانا اللذين كانا يزوران ألمانيا الغربية.', 'وتقع بلدة ويست ألموند (West Allond) في غرب البلاد.', 'والنتيجة الإيجابية هي دفع القدم نحو سطحها المخطط.', 'وسائط الإعلام البطيئة هي إمبراطورية إعلامية في الشرق، سويسرا.', 'ومثل هذه الركوبات هي مقدمة الجذبات العصرية للمتنزهات التي تُسلَّخ على الجذوع.', 'الأصباغ الحديثة المزدوجة في العملات الأمريكية يتم اكتشافها بشكل رئيسي بمعنى لينكولن.', 'وشجع أيضا تنمية صناعة التعدين والتجارة.', 'المستخدمون في منزل المستضعفين أعطوا كوف الكنز', 'واتهم مضيفوهم، الذين أنكروا في البداية وجودهم، بإيواء الخونة.', 'ثم درس طب الأسنان في فرايبورغ وميونيخ.', 'ها هي تأتي!', 'وقد استخدمت هذه الأسلحة في مرحلة الصدمة والرعب من حرب العراق.', 'وهناك أيضاً متاجر في الزوايا في العقارات.', 'انتحار (يهوذا) هو إعدام يقوم فيه (بيزلبوب) بواجب الجلاد', '(ستون) لم يتزوّج أبدًا.', 'قام بجولة في فيجي وتونغا مع إنجلترا في وقت لاحق من ذلك العام.', 'وفي وقت لاحق اختاره المحافظون كمرشح برلماني أوروبي.', 'الحظ في مخيم المتجولين هو قصة قصيرة من قبل المؤلف الأمريكي بريت هارت.', 'وهو متزوج من نانسي دورن السابق.', 'ويعرف هذا الحدث في علم علم الأحافير باسم التبادل الأمريكي الكبير.', 'مثل جميع عملات الاختبار، والفارغ البلاتينيوم له قيمة تاريخية ونوومية عالية.', '(داني) يعمل ليساعده، لكنّه متأخر جداً.', 'وجرت أيضا ترجمة انكليزية مختصرة من اللغة اللاتينية عن طريق الشراء.', 'بدأ هذا بثورة التدريب.', 'تحتوي بيرغاموت على كميات كبيرة للغاية من البوليفينول بالمقارنة مع الأنواع الأخرى من الحمضيات.', 'وقد أشير إلى نهاية المسرحية بإغلاق الستارة الأمامية.', 'وقد خدمت الوحدة في حملة بريستو.', 'العديد من هذه الموانئ هي رياس.', 'في فرنسا، كسر الرقم القياسي العالمي وحصل على علاوة مالية.', 'وساعد في وقت لاحق على إنشاء العديد من المنظمات للحفاظ على ثقافة نيبال.', 'المدرسة الإعدادية', 'وكانت الضريبة فريدة من عدة جوانب.', 'ومن بين الأسماء الأخرى التي نادراً ما تُستخدم داوني آش، ومستنقع آش، وماء آش.', 'ضحلة ساحة الأسلحة البلدية هي (أرجينت أ.', 'كانا يتشاجران أمام الصف', 'وبعد فترة وجيزة ، تبع كونسيپسيون شخصية امّه ، ميلي كيسادا .', 'الأخ الأصغر بومسونغ، يانيك بومسونغ، هو أيضا لاعب كرة قدم محترف.', 'ويقتصر منصب نائب الحاكم أيضاً على فترتين متتاليتين مدة كل منهما أربع سنوات.', 'وأصدرت المدينة في وقت لاحق بيانا عكس تفسيرها لأنظمة التوقيع.', 'وبالإضافة إلى ذلك، يجري على نحو متزايد إدراج دروس دراسية واستقصاءات حديثة ومواضيع ساخنة.', 'وهي مصممة للاستخدام المدني.', 'فَكَيْفَ نَمَى ٱلدَّعْمُ لِمُسَاعَدَتِهِ بِٱسْتِمْرَارٍ ؟', 'وكانت أيضا أول لاتينية تخرجت من مدرسة لويولا للحقوق.', 'والأنواع التجارية من الفستق لها ثمار أكبر وهي صالحة للأكل.', 'ولم يستمر هذا الترتيب طويلاً.', 'معظم ألبومه يتم تأليفها في شكل أكورديون.', 'ومن المتوقع أن تكمل الطواقم رفعة واحدة كل أسبوع.', 'بدأ الطلاب في حضور فصول في المبنى الجديد عندما عادوا من عطلة الربيع.', 'ويشمل المحللون السياسيون المدعوون المربين وأعضاء جماعات الضغط والمشرعين السابقين.', 'وبعد الحرب، أعيدت بعض التماثيل إلى هونغ كونغ.', 'كانت (شيلوه) مرة توقفاً على السكة الحديدية القديمة (وينشستر) والغربية.', 'بعد ذلك الوقت، مثّل قيادة (فانكوفر) حتى هزيمته.', 'ولجيلبرت ابن واحد وأحفادان.', 'كان محتجزاً في مقبرة (سومرفيل) في (أوغستا) بـ(جورجيا).', 'وقد نشأ كودرو في أسرة يهودية من الطبقة المتوسطة وكان له احتفال مضرب ميتزفاه.', 'كان (كينيون) ضابطاً في الجيش البريطاني الهندي', 'وقد سميت الجائزة جائزة نوبل للموسيقى في السويد.', 'لقد كنا عالقين في الطابور من قبل تلك الأعمال الطرقية لأعمار طويلة.', 'ثم يبدأ رمي الكرينجل الفعلي.', 'والمسبح عبارة عن مسبح خارجي تديره لجنة الاستجمام في جانب الكهف.', 'وُلد صموئيل إنجليزي في قرية كريبوليا في أغاداغوي بأيرلندا الشمالية.', 'وقد قُتل أو فُقد 24 شخصاً من طاقمها وأصيب 9 آخرون بجراح.', 'وهي تستهدف جمهوراً صغيراً وتملكها وتديرها شركة \" Widlegent Media Corporation \" .', 'الأسابيع هي عالم سياسي أمريكي.', 'أحب إعادة ترتيب أجزاء من الأغنية بشكل مائل واستخدم كلمات مختلفة تماما.', '(إبريل) يذهب من باب إلى باب يبحث عن منزل (وارن)', 'وهو يستخدم موجات الراديو لتأيين وتسخين الوقود الدفعي.', 'هذا هو آخر موسم يتم بثه في التعريف القياسي.', 'قناة (جيلدام)، جئت عبر القطار.', 'لقد أصبح موقف (بروترو) بارداً بشكل متزايد، منفصلاً، و تقريباً أنانياً في طبيعته.', 'عندما يكتشف (غالان) ذلك، يكون قد فات الأوان بالفعل، ويكون الضرر غير قابل للإلغاء.', '(كونز) متزوج وله ثلاثة أبناء', 'البلدة هي موطن قرية ومتحف مدينة جينيسي.', 'أجل، لقد كان (داونلي)', 'كما تظهر قيم Q في فيزياء الجسيمات.', 'ويجوز لممثلي الخزانة حضور الاجتماع، ولكن فقط بوصفهم مراقبين غير مصوتين.', 'قد تكون مهتماً بذلك', 'وكثيراً ما يشير المستعرضون المعاصرون إلى هذه الأصوات.', 'ولم يكن لديها سوى أسطول صغير جدا ولم توفر طرقا طويلة المدى.', 'كما أُصدرت حلقات من السلسلة في مجموعة لازر ديسك يابانية .']\n"
     ]
    }
   ],
   "source": [
    "Arabic_Sentences = TranslateSentence(Transcribed_Sentences)\n",
    "print(Arabic_Sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
