{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structred Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# System Libraries\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "# Garbage Collection\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\Real-Time-Speech-Recognition-and-Translation-\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "DIRECTORY_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "VALIDATED_DATA_PATH = r\"\\Common_Voice\\validated.tsv\"\n",
    "VALIDATED_SENTENCES_PATH = r\"\\Common_Voice\\unvalidated_sentences.tsv\"\n",
    "CLIP_DURATION_PATH = r\"\\Common_Voice\\clip_durations.tsv\"\n",
    "CLIPS_PATH = r\"\\Common_Voice\\clips\\\\\"\n",
    "CLIPS_WAV_PATH = r\"\\Common_Voice\\clips_wav\"\n",
    "\n",
    "# Constants\n",
    "NYQUIST_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDurations(paths):\n",
    "    duratios = []\n",
    "    for path in paths:\n",
    "        audio, sr = librosa.load(DIRECTORY_PATH + CLIPS_PATH + path)\n",
    "        duratios.append(librosa.get_duration(y=audio, sr=sr))\n",
    "    return duratios\n",
    "\n",
    "def getMaxDuration(dataframe):\n",
    "    #Get Longest Audio Clip\n",
    "    MAX_AUDIO_DURATION = max(dataframe[\"duration\"])\n",
    "    LongestAudio = dataframe[dataframe['duration'] == MAX_AUDIO_DURATION]\n",
    "    PATH_OF_LONGEST_AUDIO = DIRECTORY_PATH + CLIPS_PATH + LongestAudio[\"path\"].values[0]\n",
    "    SENTENCE_OF_LONGEST_AUDIO = LongestAudio[\"sentence\"].values[0]\n",
    "\n",
    "    # Load Audio\n",
    "    wavform, sample_rate = librosa.load(PATH_OF_LONGEST_AUDIO)\n",
    "    FRAME_LENGTH_OF_LONGEST_AUDIO = len(wavform)\n",
    "    return MAX_AUDIO_DURATION, PATH_OF_LONGEST_AUDIO, FRAME_LENGTH_OF_LONGEST_AUDIO\n",
    "\n",
    "def PreprocessAudios(paths, longestAudioFrameLength):\n",
    "    # Add Padding\n",
    "    MAXPADDING = longestAudioFrameLength\n",
    "    for path in paths:\n",
    "        wavform, sr = librosa.load(DIRECTORY_PATH + CLIPS_PATH + path)\n",
    "        padding = [0] * (MAXPADDING - len(wavform))\n",
    "        wavform = np.concatenate((wavform, padding))\n",
    "        wavform = librosa.resample(wavform, orig_sr=sr, target_sr=NYQUIST_SAMPLING_RATE)\n",
    "        wavform = librosa.util.normalize(wavform)\n",
    "        sf.write(DIRECTORY_PATH + CLIPS_WAV_PATH + \"\\\\\" + path[:-4] + \".wav\", wavform, sr, format='wav')\n",
    "\n",
    "def getMFCCs(paths):\n",
    "    wavform, sr = librosa.load(DIRECTORY_PATH + CLIPS_WAV_PATH + \"\\\\\" + paths[0])\n",
    "    mfccs = librosa.feature.mfcc(y=wavform, n_mfcc=13, sr=sr, n_fft=2048, hop_length=512)\n",
    "    mfccs = mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1])\n",
    "    for path in paths[1:]:\n",
    "        wav , sr = librosa.load(DIRECTORY_PATH + CLIPS_WAV_PATH + \"\\\\\" + path)\n",
    "        mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13, sr=sr, n_fft=2048, hop_length=512)\n",
    "        mfccs = np.concatenate((mfccs, mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])), axis=0)\n",
    "    return mfccs\n",
    "\n",
    "def getTokenizedSentences(sentences):\n",
    "    # Start Code (Ahmad Elsayed)\n",
    "\n",
    "    # End Code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13, 334)\n"
     ]
    }
   ],
   "source": [
    "wavform, sr = librosa.load(\"D:\\ML\\Real-Time-Speech-Recognition-and-Translation-\\Common_Voice\\clips_wav\\common_voice_en_40189607.wav\")\n",
    "mfcc = librosa.feature.mfcc(y=wavform, n_mfcc=13, sr=sr, n_fft=2048, hop_length=512)\n",
    "mfccs = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "print(mfccs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['client_id', 'path', 'sentence_id', 'sentence', 'sentence_domain',\n",
      "       'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant',\n",
      "       'locale', 'segment', 'duration'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(valid_clips_duration.columns)[[\"path\", \"sentence\", \"up_votes\", \"duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_dataset = pd.read_csv(DIRECTORY_PATH + VALIDATED_DATA_PATH , sep='\\t')[[\"path\", \"sentence\", \"up_votes\"]]\n",
    "durations = getDurations(unfiltered_dataset[\"path\"].tolist())\n",
    "unfiltered_dataset[\"duration\"] = durations\n",
    "longestAudioDuration ,  longestAudioPath, longestAudioFrameLength = getMaxDuration(unfiltered_dataset)\n",
    "PreprocessAudios(unfiltered_dataset[\"path\"].tolist(), longestAudioFrameLength)\n",
    "unfiltered_dataset['path'] = unfiltered_dataset['path'].str.replace('.mp3', '.wav', regex=False)\n",
    "\n",
    "# For you Ahmad Elsayed uses the following sentences in the following line\n",
    "sentences = unfiltered_dataset[\"sentence\"].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
